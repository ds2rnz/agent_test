import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from datetime import datetime

import pytz
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from dotenv import load_dotenv
import os

from typing import TypedDict, Annotated, List
from langgraph.graph import StateGraph, END
from langchain_community.document_loaders import PyPDFLoader
 #from langchain.text_splitter import RecursiveCharacterTextSplitter
import tempfile
import ast

# from langchain.chains import RetrievalQA
from langchain_openai import OpenAIEmbeddings
# from langchain_chroma import Chroma
# from langchain.agents import PromptTemplate
from langchain_community.vectorstores import FAISS
from openai import OpenAI

import concurrent.futures
import traceback
import inspect
import time

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI()

llm = ChatOpenAI(
    model="gpt-5",
    temperature=0.4,
    timeout=30,  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    max_retries=2 ) 




def debug_wrap(func):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œ ì—ëŸ¬ë‚˜ ì¤‘ë‹¨ì ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë””ë²„ê¹… ë˜í¼"""
    def wrapper(*args, **kwargs):
        func_name = func.__name__
        try:
            st.write(f"[DEBUG] â–¶ ì‹¤í–‰ ì‹œì‘: {func_name}")
            result = func(*args, **kwargs)
            st.write(f"[DEBUG] âœ… ì‹¤í–‰ ì„±ê³µ: {func_name}")
            return result
        except Exception as e:
            tb = traceback.format_exc()
            st.write(f"\n[ERROR] âŒ í•¨ìˆ˜ '{func_name}' ì—ì„œ ì˜ˆì™¸ ë°œìƒ:")
            st.write(f"  â””â”€ {e}")
            st.write(tb)
            st.error(f"âŒ í•¨ìˆ˜ '{func_name}' ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.code(tb, language="python")
            raise
    return wrapper




# -- ë„êµ¬ ì •ì˜ --
# @tool
# def get_current_time(timezone: str, location: str) -> str:
#     """í˜„ì¬ ì‹œê°„ì„ ì§€ì •ëœ íƒ€ì„ì¡´ê³¼ ìœ„ì¹˜ì— ë§ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤."""
#     import pytz
#     from datetime import datetime
#     try:
#         tz = pytz.timezone(timezone)
#         now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
#         return f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
#     except pytz.UnknownTimeZoneError:
#         return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"

# @tool
# def get_web_search(query: str, search_period: str) -> str:
#     """DuckDuckGo APIë¥¼ ì´ìš©í•´ ì§€ì •ëœ ê¸°ê°„ ë‚´ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
#     wrapper = DuckDuckGoSearchAPIWrapper(region="kr-kr", time=search_period)
#     search = DuckDuckGoSearchResults(api_wrapper=wrapper, source="news", results_separator=';\n')
#     return search.invoke(query)

# tools = [get_current_time, get_web_search]
# tool_dict = {tool.name: tool for tool in tools}
# llm_with_tools = llm.bind_tools(tools)


@debug_wrap
def get_ai_response(messages):
    response = llm.invoke(messages)
    return response





# --- Streamlit ì•± ì„¤ì • ---
st.set_page_config(page_title="AI ë„ìš°ë¯¸", page_icon="ğŸ’¬", layout="wide")

st.title("ğŸ’¬ ê³ ì„±êµ°ì²­ :blue[AI] ë„ìš°ë¯¸")


# --- í™”ë©´ ë””ìì¸ ---
st.markdown("""
    <style>
    /* ê¸°ë³¸ ë°”ë”” í°íŠ¸ ë° ë°°ê²½ */
    body {
        background-color: #f0f2f6;
        font-family: 'Noto Sans KR', sans-serif;
        color: #333;
    }

    
     /* ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ */
    .stChatInput input {
        border: 2px solid #3b82f6;
        border-radius: 25px;
        padding: 15px 25px;
        font-size: 16px;
        background: linear-gradient(to right, #f0f9ff, #ffffff);
        transition: all 0.3s ease;
    }
    
    .stChatInput input:focus {
        border-color: #2563eb;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
        background: white;
    }
    
    .stChatInput button {
        background: linear-gradient(135deg, #3b82f6, #2563eb);
        border-radius: 50%;
        transition: transform 0.3s ease;
    }
    
    .stChatInput button:hover {
        transform: scale(1.1) rotate(15deg);
    }

    </style>
""", unsafe_allow_html=True)

animated_input_css = """
    <style>
    /* ì…ë ¥ì°½ ë“±ì¥ ì• ë‹ˆë©”ì´ì…˜ */
    .stChatInput {
        animation: slide-up 0.5s ease-out;
    }
    
    @keyframes slide-up {
        from {
            opacity: 0;
            transform: translateY(50px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* íƒ€ì´í•‘ íš¨ê³¼ */
    .stChatInput input:focus {
        animation: typing-glow 2s ease-in-out infinite;
    }
    
    @keyframes typing-glow {
        0%, 100% { box-shadow: 0 0 5px rgba(59, 130, 246, 0.3); }
        50% { box-shadow: 0 0 20px rgba(59, 130, 246, 0.6); }
    }
    
    /* ë²„íŠ¼ íšŒì „ íš¨ê³¼ */
    .stChatInput button:hover {
        animation: rotate 0.5s ease;
    }
    
    @keyframes rotate {
        from { transform: rotate(0deg); }
        to { transform: rotate(360deg); }
    }
    </style>
"""

st.markdown(animated_input_css, unsafe_allow_html=True)

   

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ì €ëŠ” ê³ ì„±êµ°ì²­ ì§ì›ì„ ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "),  
        AIMessage("ë¬´ì—‡ì„ ë„ì™€ ë“œë¦´ê¹Œìš”?")
    ]

if "vectorstore" not in st.session_state:
    st.session_state["vectorstore"] = None

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input(placeholder="âœ¨ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”?"):
    st.chat_message("user").write(prompt)
    st.session_state.messages.append(HumanMessage(prompt))

    # vectorstore ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if st.session_state.get("vectorstore") is not None:
        # ë²¡í„°ìŠ¤í† ì–´ ê¸°ë°˜ ë‹µë³€
        st.write("ğŸ“š í•™ìŠµëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤...")
        answer = get_ai_response(prompt)
        
    else:
        st.write("ğŸ¤– ì¼ë°˜ AI ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤...")
        response = get_ai_response(st.session_state["messages"])
        result = st.chat_message("assistant").write_stream(response)
        st.session_state.messages.append(AIMessage(result)) 
else:
    # ê¸°ì¡´ ë„êµ¬ ê²°í•© LLM ë‹µë³€
    st.write("ğŸ¤– ì¼ë°˜ AI ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤...")
    response = llm.invoke(st.session_state["messages"])
    result = st.chat_message("assistant").write_stream(response)
    st.session_state.messages.append(AIMessage(result)) 











